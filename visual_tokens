# pip install taming-transformers-rom1504
import torch
from taming.models.vqgan import VQModel

def load_vqgan():
    # Download the checkpoint and config for 'vqgan_imagenet_f16_16384'
    # Config: https://heibox.uni-heidelberg.de/f/867b05fc8c4f41768640/?dl=1
    # CKPT: https://heibox.uni-heidelberg.de/f/0e42f04e2e904890a9b6/?dl=1
    config_path = "vqgan_imagenet_f16_16384.yaml"
    ckpt_path = "vqgan_imagenet_f16_16384.ckpt"
    
    model = VQModel.load_from_checkpoint(config_path=config_path, checkpoint_path=ckpt_path)
    model.eval().cuda()
    return model

def encode_image(image_tensor, model):
    # image_tensor: [B, 3, 256, 256] normalized to [-1, 1]
    with torch.no_grad():
        z, _, [indices] = model.encode(image_tensor)
    return indices.reshape(-1) # Returns flat list of integers (0-16383)

def decode_tokens(indices, model):
    # indices: [B, 256]
    z_q = model.quantize.get_codebook_entry(indices, shape=(1, 16, 16, 256))
    decoded_img = model.decode(z_q)
    return decoded_img